{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import division\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        (x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = tf.keras.datasets.mnist.load_data()\n",
    "        \n",
    "        #Flatten the training and test images\n",
    "        x_train_flat = x_train_orig.reshape(x_train_orig.shape[0], -1)\n",
    "        x_test_flat = x_test_orig.reshape(x_test_orig.shape[0], -1)\n",
    "        \n",
    "        (self.m, self.n_x) = x_train_flat.shape\n",
    "        self.n_y = 10  \n",
    "        \n",
    "        #Normalize image vectors\n",
    "        self.x_train = x_train_flat / np.float32(255)\n",
    "        self.x_test = x_test_flat / np.float32(255)        \n",
    "            \n",
    "        #Convert training and test labels to on hot matrices\n",
    "        self.y_train = self.one_hot(y_train_orig, self.n_y)\n",
    "        self.y_test = self.one_hot(y_test_orig, self.n_y)                     \n",
    "           \n",
    "    def one_hot(self, labels, numclasses):\n",
    "        return np.eye(numclasses)[labels]\n",
    "    \n",
    "    #def create_variables(self):\n",
    "    #    with tf.variable_scope(\"variables\"):\n",
    "    #        W1 = tf.get_variable(\"W1\", [self.n_x, 500], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    #        b1 = tf.get_variable(\"b1\", [1, 500], initializer = tf.zeros_initializer())\n",
    "    #        W2 = tf.get_variable(\"W2\", [500, 500], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    #        b2 = tf.get_variable(\"b2\", [1, 500], initializer = tf.zeros_initializer())\n",
    "    #        W3 = tf.get_variable(\"W3\", [500, 10], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    #        b3 = tf.get_variable(\"b3\", [1, 10], initializer = tf.zeros_initializer()) \n",
    "        \n",
    "    #Test\n",
    "    def fully_connected(self, A_prev, nbr_inputs, nbr_outputs):\n",
    "        W = tf.get_variable(\"W\", [nbr_inputs, nbr_outputs], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "        b = tf.get_variable(\"b\", [1, nbr_outputs], initializer = tf.zeros_initializer())            \n",
    "        Z = tf.add(tf.matmul(A_prev, W), b)\n",
    "        A = tf.nn.relu(Z)\n",
    "        return A\n",
    "        \n",
    "    def forward_propagation(self, X):\n",
    "        with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE):\n",
    "            A1 = self.fully_connected(X, 784, 500)\n",
    "        with tf.variable_scope(\"layer2\", reuse=tf.AUTO_REUSE):\n",
    "            A2 = self.fully_connected(A1, 500, 500)\n",
    "        with tf.variable_scope(\"layer3\", reuse=tf.AUTO_REUSE):\n",
    "            A3 = self.fully_connected(A2, 500, 10)\n",
    "            return A3\n",
    "        \n",
    "    #def forward_propagation(self, X):\n",
    "    #    with tf.variable_scope(\"variables\", reuse=True):\n",
    "    #        W1 = tf.get_variable(\"W1\")\n",
    "    #        b1 = tf.get_variable(\"b1\")\n",
    "    #        W2 = tf.get_variable(\"W2\")\n",
    "    #        b2 = tf.get_variable(\"b2\")\n",
    "    #        W3 = tf.get_variable(\"W3\")\n",
    "    #        b3 = tf.get_variable(\"b3\") \n",
    "    #    \n",
    "    #        Z1 = tf.add(tf.matmul(X, W1), b1)\n",
    "    #        A1 = tf.nn.relu(Z1)\n",
    "    #        Z2 = tf.add(tf.matmul(A1, W2), b2)\n",
    "    #        A2 = tf.nn.relu(Z2)\n",
    "    #        Z3 = tf.add(tf.matmul(A2, W3), b3)\n",
    "    #        return Z3\n",
    "\n",
    "    def compute_loss(self, predicted, actual):              \n",
    "        total_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = predicted, labels = actual)\n",
    "        avg_loss = tf.reduce_mean(total_loss)    \n",
    "        return avg_loss\n",
    "    \n",
    "    def create_optimizer(self, learning_rate):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def compute_accuracy(self, predicted, actual):\n",
    "        correct_prediction = tf.equal(tf.argmax(predicted, axis=1), tf.argmax(actual, axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        return accuracy                 \n",
    "        \n",
    "    def train(self, num_epochs = 100):\n",
    "    \n",
    "        BATCH_SIZE = 1000\n",
    "    \n",
    "        tf.reset_default_graph()\n",
    "        tf.set_random_seed(1)\n",
    "\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_x])\n",
    "        y = tf.placeholder(tf.float32, shape=[None, self.n_y])\n",
    "\n",
    "        # Define training dataset\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(self.m).batch(BATCH_SIZE).repeat()        \n",
    "        train_iterator = train_dataset.make_initializable_iterator()        \n",
    "        train_features, train_labels = train_iterator.get_next()    \n",
    "        train_init_op = train_iterator.make_initializer(train_dataset) \n",
    "\n",
    "        #self.create_variables()\n",
    "        \n",
    "        #Training\n",
    "        train_predicted = self.forward_propagation(train_features)        \n",
    "        loss = self.compute_loss(train_predicted, train_labels)        \n",
    "        optimizer = self.create_optimizer(0.001).minimize(loss)\n",
    "\n",
    "        #Compute accuracy\n",
    "        test_predicted = self.forward_propagation(x)                \n",
    "        accuracy = self.compute_accuracy(test_predicted, y)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            sess.run(train_init_op, feed_dict = {x : self.x_train, y: self.y_train})\n",
    "                 \n",
    "            nbrOfBatches = self.m // BATCH_SIZE\n",
    "\n",
    "            begin_time = time.time()\n",
    "            for epoch in range(num_epochs):\n",
    "\n",
    "                epoch_loss = 0\n",
    "                \n",
    "                for _ in range(nbrOfBatches):\n",
    "                    _, batch_loss = sess.run([optimizer, loss])\n",
    "                    epoch_loss += batch_loss\n",
    "\n",
    "                train_accuracy = sess.run(accuracy, feed_dict = {x: self.x_train, y: self.y_train})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict = {x: self.x_test, y: self.y_test})\n",
    "                \n",
    "                if (epoch % 10 == 0):\n",
    "                    print(\"epoch: {}, train_loss: {:.4f}, train_accuracy: {:.4f}, test_accuracy: {:.4f}\".format(\n",
    "                        epoch, \n",
    "                        epoch_loss / nbrOfBatches, \n",
    "                        train_accuracy,\n",
    "                        test_accuracy\n",
    "                    ))\n",
    "                \n",
    "            end_time = time.time()\n",
    "\n",
    "            print('Model trained in {:.3f} (hh:mm:ss.ms)'.format(end_time - begin_time))\n",
    "                     \n",
    "            train_accuracy = sess.run(accuracy, feed_dict = {x: self.x_train, y: self.y_train})\n",
    "            print(\"Accuracy on training set: {:.4f}\".format(train_accuracy))\n",
    "                \n",
    "            test_accuracy = sess.run(accuracy, feed_dict = {x: self.x_test, y: self.y_test})\n",
    "            print(\"Accuracy on test set: {:.4f}\".format(test_accuracy))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Me\\Anaconda3\\envs\\tfp3.6\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "epoch: 0, train_loss: 0.6807, train_accuracy: 0.8583, test_accuracy: 0.8544\n",
      "epoch: 10, train_loss: 0.2425, train_accuracy: 0.8991, test_accuracy: 0.8836\n",
      "epoch: 20, train_loss: 0.2316, train_accuracy: 0.8999, test_accuracy: 0.8845\n",
      "epoch: 30, train_loss: 0.2307, train_accuracy: 0.8999, test_accuracy: 0.8849\n",
      "epoch: 40, train_loss: 0.2306, train_accuracy: 0.8999, test_accuracy: 0.8852\n",
      "epoch: 50, train_loss: 0.0231, train_accuracy: 0.9975, test_accuracy: 0.9789\n",
      "epoch: 60, train_loss: 0.0005, train_accuracy: 0.9999, test_accuracy: 0.9838\n",
      "epoch: 70, train_loss: 0.0004, train_accuracy: 0.9999, test_accuracy: 0.9836\n",
      "epoch: 80, train_loss: 0.0003, train_accuracy: 0.9999, test_accuracy: 0.9834\n",
      "epoch: 90, train_loss: 0.0003, train_accuracy: 0.9999, test_accuracy: 0.9834\n",
      "Model trained in 436.167 (hh:mm:ss.ms)\n",
      "Accuracy on training set: 0.9996\n",
      "Accuracy on test set: 0.9828\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
